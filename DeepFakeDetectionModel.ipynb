{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/avilaJorge/CSE253_FinalProject/blob/master/DeepFakeDetectionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run DeepFake_Dataloader.py\n",
    "%run utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrLJOWM70-3i"
   },
   "outputs": [],
   "source": [
    "# imports pytorch\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Numpy, Matplotlib, and PIL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# general imports\n",
    "import pprint\n",
    "\n",
    "# My imports\n",
    "from DeepFake_Dataloader import get_dataloaders\n",
    "from models import LinearRegression, save_model\n",
    "from utils import RunningAverage\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PGIMYckCTfS9"
   },
   "outputs": [],
   "source": [
    "trn_dl, val_dl, tst_dl = get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "yzicYWt7MEaO",
    "outputId": "885c570d-d043-4703-b585-ee3e097783bc"
   },
   "outputs": [],
   "source": [
    "# img2 = Image.open('./Frequency/Faces-HQ/celebA-HQ_10K/0.jpg')\n",
    "# # display(img2)\n",
    "# img2 = img2.convert('L')\n",
    "\n",
    "# mag_spectrum = np_magnitude_spectrum(img2)\n",
    "# rad2 = np_radial_profile(mag_spectrum, center=(mag_spectrum.shape[0]/2, mag_spectrum.shape[1]/2))\n",
    "# plt.plot(rad2)\n",
    "# plt.show()\n",
    "\n",
    "# rad_p, t = next(iter(trn_dl))\n",
    "# rad_p = rad_p.squeeze(0)\n",
    "# # t_img = torch.from_numpy(np.asarray(img2)).squeeze(0).float()\n",
    "# # ms = magnitude_spectrum(t_img)\n",
    "# # rad2 = radial_profile(ms, center=(ms.shape[0]/2, ms.shape[1]/2))\n",
    "# plt.plot(rad_p.cpu())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_epoch      = 1\n",
    "num_epochs   = 100\n",
    "log_step     = 10\n",
    "lr_rate      = 1e-5\n",
    "best_loss    = float('inf')\n",
    "prev_loss    = float('inf')\n",
    "loss_inc_cnt = 0\n",
    "stop_early   = False\n",
    "load_model   = False\n",
    "model_name   = 'LogisticRegressionModel'\n",
    "\n",
    "lr_model = LinearRegression(725, 250, 1).to(device)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(lr_model.parameters(), lr=lr_rate)\n",
    "\n",
    "if load_model:\n",
    "    lr_model.load_state_dict(torch.load(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, validation_loader):\n",
    "    \n",
    "    # Train the models\n",
    "    total_step = len(dataloader)\n",
    "    for epoch in range(s_epoch, num_epochs):\n",
    "        ts = time.time()\n",
    "        print_info(\"----- Starting Training Epoch lr=%.8f best_loss=%f ------\\n\" \n",
    "                   % (lr_rate, best_loss))\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move to GPU\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Forward, backward and optimize\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss=loss.item()\n",
    "            \n",
    "            # Print log info\n",
    "            if i % log_step == 0:\n",
    "                print_info('\"Epoch\": [{}/{}], \"Step\": [{}/{}], \"Loss\": {:.4f} \\n'\n",
    "                      .format(epoch, num_epochs, i, total_step, loss))\n",
    "                \n",
    "        print_info(\"Finished Training. Time elapsed %f \\n\" % (time.time() - ts))\n",
    "\n",
    "        loss = evaluate(model, epoch, dataloader, validation=False)\n",
    "        print_info('\"Training Epoch Done\": \"Epoch\": [{}/{}], \"Loss\": {:.4f} \\n'\n",
    "                      .format(epoch, num_epochs, loss)) \n",
    "        \n",
    "        loss = evaluate(model, epoch, validation_loader) \n",
    "        print_info('\"Validation Epoch Done\": \"Epoch\": [{}/{}], \"Loss\": {:.4f} \\n'\n",
    "                      .format(epoch, num_epochs, loss))\n",
    "\n",
    "def evaluate(model, epoch, data_loader, validation=True):\n",
    "\n",
    "    global best_loss\n",
    "    global prev_loss\n",
    "    global loss_inc_cnt\n",
    "    global stop_early\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        losses = RunningAverage()\n",
    "        ts = time.time()\n",
    "        print_info(\"----- Starting Evaluation ------\\n\")\n",
    "        total_step = len(data_loader)\n",
    "        \n",
    "        for i, (x, y) in enumerate(data_loader):\n",
    "\n",
    "            # Move to GPU\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Evaluate\n",
    "            pred = model(x)\n",
    "            losses.update(criterion(pred, y).item())\n",
    "\n",
    "        print_info(\"Finished evaluation. Time elapsed %f \\n\" % (time.time() - ts))\n",
    "        loss = losses.value\n",
    "\n",
    "        if validation:\n",
    "            if best_loss > loss:\n",
    "                best_loss = loss\n",
    "                print_info('\"Best Loss\": ' + str(best_loss) + '\\n')\n",
    "                save_model(model, 'Best-' + model_name, dt, path)\n",
    "\n",
    "            loss_inc_cnt = loss_inc_cnt + 1 if prev_loss < loss else 0\n",
    "            if loss_inc_cnt > 2: stop_early = True\n",
    "            save_model(model, model_name, dt, path)\n",
    "            print_info(\"Validation Loss has gone up %d times.\\n\" % (loss_inc_cnt))\n",
    "            prev_loss = loss\n",
    "        \n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(lr_model, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNYwy8pk5RP1WfSlFR9Do+P",
   "include_colab_link": true,
   "machine_shape": "hm",
   "mount_file_id": "1oUma_1hYvI7_NNVnKvHgVAbI1Y2xWoxt",
   "name": "DeepFakeDetectionModel",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
